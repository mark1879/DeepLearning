{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea47fc6c",
   "metadata": {},
   "source": [
    "### 张量的保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3ef8eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97bd5c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3341, 0.9801, 0.9024, 0.9792, 0.8991, 0.8544])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(6)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7807402a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3341, 0.9801, 0.9024, 0.9792, 0.8991, 0.8544])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(a, \"models/tensor_a\")\n",
    "torch.load(\"models/tensor_a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b73bc6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2068, 0.1687, 0.1243, 0.6716, 0.8314, 0.0648]),\n",
       " tensor([0.4220, 0.9659, 0.9497, 0.6557, 0.9215, 0.9614]),\n",
       " tensor([0.2321, 0.8685, 0.7852, 0.0403, 0.1495, 0.0018])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(6)\n",
    "b = torch.rand(6)\n",
    "c = torch.rand(6)\n",
    "[a,b,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2176b472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2068, 0.1687, 0.1243, 0.6716, 0.8314, 0.0648]),\n",
       " tensor([0.4220, 0.9659, 0.9497, 0.6557, 0.9215, 0.9614]),\n",
       " tensor([0.2321, 0.8685, 0.7852, 0.0403, 0.1495, 0.0018])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save([a,b,c],\"models/tensor_abc\")\n",
    "torch.load(\"models/tensor_abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "144b6047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([0.2068, 0.1687, 0.1243, 0.6716, 0.8314, 0.0648]),\n",
       " 'b': tensor([0.4220, 0.9659, 0.9497, 0.6557, 0.9215, 0.9614]),\n",
       " 'c': tensor([0.2321, 0.8685, 0.7852, 0.0403, 0.1495, 0.0018])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_dict= {'a':a,'b':b,'c':c}\n",
    "tensor_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc430ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': tensor([0.2068, 0.1687, 0.1243, 0.6716, 0.8314, 0.0648]),\n",
       " 'b': tensor([0.4220, 0.9659, 0.9497, 0.6557, 0.9215, 0.9614]),\n",
       " 'c': tensor([0.2321, 0.8685, 0.7852, 0.0403, 0.1495, 0.0018])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(tensor_dict,\"models/tensor_dict_abc\")\n",
    "torch.load(\"models/tensor_dict_abc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ab3b2",
   "metadata": {},
   "source": [
    "### 模型的保存与加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae0110f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "input_size = 28 * 28 \n",
    "hidden_size = 512\n",
    "num_classes = 10 \n",
    "\n",
    "model = MLP(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7510f72b",
   "metadata": {},
   "source": [
    "### 方式1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b811d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/mlp_state_dict.pth\")\n",
    "\n",
    "\n",
    "model_load = MLP(input_size,hidden_size,num_classes)\n",
    "\n",
    "# 调用load_state_dict方法 传入读取的参数\n",
    "mlp_state_dict = torch.load(\"models/mlp_state_dict.pth\")\n",
    "model_load.load_state_dict(mlp_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "898a56a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.0206, -0.0345, -0.0221,  ..., -0.0337, -0.0355, -0.0160],\n",
       "                      [ 0.0206, -0.0106, -0.0086,  ..., -0.0176, -0.0002, -0.0165],\n",
       "                      [-0.0026,  0.0066, -0.0275,  ..., -0.0213, -0.0344,  0.0355],\n",
       "                      ...,\n",
       "                      [-0.0135, -0.0179,  0.0132,  ...,  0.0183,  0.0195,  0.0219],\n",
       "                      [ 0.0245,  0.0243,  0.0177,  ...,  0.0153,  0.0224, -0.0353],\n",
       "                      [-0.0168, -0.0053,  0.0267,  ..., -0.0211,  0.0225, -0.0102]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 3.1718e-02, -1.4874e-02, -7.9082e-03, -3.6069e-03,  2.0391e-02,\n",
       "                       2.1254e-02, -3.2543e-02,  1.6261e-02, -7.1722e-03, -1.9165e-02,\n",
       "                      -2.1806e-03,  1.5472e-02,  3.1557e-02,  2.7973e-02,  1.1014e-02,\n",
       "                       2.9658e-02, -3.1161e-02,  1.5704e-02,  1.0121e-02, -8.0777e-03,\n",
       "                       2.4534e-02, -9.0364e-03,  4.4785e-03, -3.6612e-03, -3.3022e-03,\n",
       "                       3.0673e-02,  2.8601e-02,  8.9696e-03,  2.8674e-02, -2.6070e-02,\n",
       "                      -1.3957e-02,  1.4492e-02, -3.2094e-02, -5.5128e-03,  3.5878e-05,\n",
       "                      -1.8781e-02,  1.5703e-02,  8.7920e-03, -1.8771e-02, -6.1205e-03,\n",
       "                       1.0556e-03,  5.7756e-03, -2.8246e-02, -1.0094e-02,  1.1835e-03,\n",
       "                       5.8360e-03,  2.9134e-02, -2.8009e-02, -2.7731e-02, -3.0176e-02,\n",
       "                       2.7577e-02,  3.3761e-02,  2.2768e-02,  3.2296e-02, -1.2306e-02,\n",
       "                      -9.9662e-04,  1.6387e-03, -8.5897e-03,  8.5609e-03,  2.0687e-02,\n",
       "                       1.3326e-02, -8.3609e-03, -1.4595e-02, -1.1619e-02, -3.3865e-02,\n",
       "                      -4.7391e-03, -2.9293e-02, -1.3884e-02,  3.5333e-02, -2.8726e-02,\n",
       "                      -5.5534e-03,  1.1638e-02,  1.5066e-02, -4.4630e-04,  3.2492e-02,\n",
       "                      -6.0212e-03, -3.4113e-02, -5.6505e-03, -1.6386e-03,  8.5610e-03,\n",
       "                       1.0095e-02, -2.1624e-02,  3.8399e-03, -3.2609e-02,  2.5248e-02,\n",
       "                      -2.7830e-02, -1.9867e-02, -8.4459e-03, -3.5475e-02,  5.0358e-03,\n",
       "                      -1.3539e-02,  3.4899e-02, -1.4449e-03, -1.5089e-02,  3.1211e-02,\n",
       "                      -3.1252e-02,  5.4308e-03,  1.4643e-02, -2.5611e-02, -2.2763e-02,\n",
       "                      -2.1283e-02, -1.2122e-03, -1.6835e-02,  2.2918e-03, -3.3920e-02,\n",
       "                      -2.4084e-02, -1.1291e-02,  4.9609e-03,  2.6250e-02,  1.0446e-02,\n",
       "                      -1.0580e-02,  5.6637e-04, -5.4054e-03,  3.3679e-02, -1.4850e-02,\n",
       "                      -2.9549e-02,  2.5131e-02, -4.4534e-04, -2.9932e-03,  3.3531e-02,\n",
       "                      -2.1799e-02, -2.1079e-02,  3.1453e-02, -7.2665e-03,  3.1480e-02,\n",
       "                       2.5180e-02,  1.8587e-02, -1.0332e-02, -1.6976e-02, -3.2588e-03,\n",
       "                       1.9415e-02, -2.8335e-02, -2.9309e-02, -2.9369e-02, -5.9951e-03,\n",
       "                       2.0638e-02,  6.4194e-03, -8.8955e-03, -3.0061e-02,  3.1458e-02,\n",
       "                      -1.3271e-02,  7.6469e-05,  9.3293e-03,  1.7535e-02,  1.3821e-02,\n",
       "                       1.9522e-02,  2.4371e-02,  3.2098e-02,  2.5028e-02,  3.2434e-02,\n",
       "                       3.0433e-02, -3.2680e-02, -3.4918e-02, -3.5484e-02,  1.1201e-02,\n",
       "                       1.6932e-02, -2.7223e-02,  4.0928e-03,  1.3461e-03,  3.4691e-02,\n",
       "                       2.9047e-02,  2.9028e-02,  3.2857e-02,  2.3409e-02, -2.5476e-03,\n",
       "                      -2.3084e-02, -1.5402e-03, -2.7045e-03, -1.2681e-02, -1.3209e-02,\n",
       "                      -1.9644e-02, -3.1536e-02,  1.7316e-02, -2.7790e-02,  3.4472e-04,\n",
       "                       2.6783e-02,  1.7165e-03, -4.3398e-03,  7.3713e-03, -4.7707e-03,\n",
       "                      -4.1568e-03,  6.6480e-03,  2.7267e-02,  1.3070e-02,  2.9740e-02,\n",
       "                       3.4915e-02, -5.1416e-04,  2.7678e-02, -1.5097e-02, -1.0361e-02,\n",
       "                       2.7520e-02, -1.7497e-02,  3.4429e-02,  1.0556e-02, -7.4099e-03,\n",
       "                      -1.4788e-02,  2.0088e-02,  1.7443e-02,  2.2176e-02, -3.0984e-02,\n",
       "                      -1.2287e-02, -2.7130e-02, -2.7293e-02,  1.1734e-02,  2.6476e-02,\n",
       "                      -1.3693e-02, -1.2241e-02,  1.9914e-02, -1.0379e-02,  1.9023e-02,\n",
       "                       2.5473e-02,  1.8132e-02, -7.1642e-03, -3.0983e-02,  3.2424e-03,\n",
       "                      -2.6353e-02, -1.3458e-02, -1.3051e-02, -1.3200e-02, -3.3809e-02,\n",
       "                       2.6923e-02,  3.1886e-02,  2.0547e-02,  2.4599e-02,  1.5379e-02,\n",
       "                      -1.5644e-02,  1.5196e-02,  1.5123e-02, -2.4331e-02, -2.3735e-02,\n",
       "                       1.2103e-02,  1.6772e-02,  3.3954e-02, -1.2235e-03,  2.0974e-02,\n",
       "                       2.1901e-02,  8.3195e-03, -1.8364e-03, -2.7597e-02,  2.1988e-02,\n",
       "                       1.4623e-02, -2.3821e-02,  1.9424e-02,  2.9142e-02, -2.4022e-02,\n",
       "                       1.5045e-03,  1.4371e-02,  2.6503e-02,  1.6448e-02,  2.7252e-02,\n",
       "                      -1.0890e-02,  9.9014e-03,  2.4965e-02, -6.9019e-03, -1.4597e-02,\n",
       "                       2.7233e-02,  2.8637e-02,  3.0903e-02, -1.4394e-02, -2.5237e-02,\n",
       "                      -4.3551e-03, -3.1043e-02,  4.7261e-03,  1.4231e-02,  6.2855e-03,\n",
       "                      -1.6938e-02,  2.6564e-02, -1.3755e-02, -1.9908e-03, -4.2515e-03,\n",
       "                      -2.1477e-02, -1.5524e-02,  2.0121e-02,  2.5465e-02, -5.3958e-03,\n",
       "                       3.0918e-02,  3.1292e-02,  1.4726e-02, -2.3371e-02, -3.0676e-02,\n",
       "                       8.4789e-03,  2.0052e-02, -2.6919e-02,  1.4755e-03,  2.2090e-02,\n",
       "                       3.4246e-02, -1.8962e-02,  7.7875e-03, -1.8316e-02,  4.9123e-03,\n",
       "                       3.4846e-02, -1.7741e-02,  5.5691e-03, -7.9257e-03,  1.5341e-02,\n",
       "                       1.6417e-03,  1.6621e-03, -1.2487e-03,  3.2241e-02, -3.2570e-03,\n",
       "                      -9.6978e-03, -8.7984e-03,  3.2644e-02,  3.4382e-02, -3.0360e-02,\n",
       "                      -1.9958e-02,  3.3395e-03,  8.5411e-04, -2.7859e-02, -3.2512e-02,\n",
       "                       3.1123e-02,  2.3224e-02, -1.6018e-02,  5.4985e-03, -1.4287e-03,\n",
       "                      -1.6523e-02,  9.8604e-03, -7.8088e-03, -1.8086e-02,  1.1592e-02,\n",
       "                       1.2471e-02, -3.4500e-02, -1.4380e-02, -3.3673e-02, -1.3032e-02,\n",
       "                      -5.2926e-03, -1.0549e-02,  1.6783e-02,  1.3649e-02,  3.4672e-02,\n",
       "                       1.2234e-02, -2.1602e-02,  2.9669e-02, -2.2051e-02,  1.5941e-02,\n",
       "                      -1.6289e-02,  1.2217e-02,  2.6937e-02, -3.2453e-02, -2.8115e-02,\n",
       "                      -6.7428e-03,  7.6960e-03,  8.6227e-03, -7.4781e-03,  2.2397e-02,\n",
       "                      -2.4387e-02,  1.7590e-02,  7.0420e-03,  2.4778e-03, -2.9818e-02,\n",
       "                       3.5624e-02, -3.0904e-02,  2.5348e-02, -1.6776e-02, -5.3809e-03,\n",
       "                       1.8129e-02,  2.7084e-02,  2.2551e-03,  7.2840e-03, -2.5558e-03,\n",
       "                      -3.3571e-02,  9.9341e-04, -2.7392e-02,  2.6892e-02, -6.4508e-03,\n",
       "                      -2.9993e-02,  2.9987e-02, -5.2459e-03, -1.3322e-02,  7.1931e-03,\n",
       "                       3.3583e-02,  1.1095e-02,  4.5849e-03, -1.1534e-02, -3.2465e-02,\n",
       "                       2.7567e-02, -1.1436e-02, -1.9450e-02, -9.3054e-05, -2.4682e-02,\n",
       "                       1.0205e-02, -1.1803e-02,  1.2602e-02, -2.1751e-02,  3.2147e-02,\n",
       "                       2.1887e-02, -2.1075e-02, -2.0157e-02, -1.7702e-02, -1.8423e-02,\n",
       "                      -2.9409e-02, -3.2479e-02,  3.1049e-03, -2.2084e-04,  1.5110e-02,\n",
       "                       5.2464e-03,  3.1583e-02, -1.8811e-02, -1.4448e-02,  1.6356e-02,\n",
       "                       1.4368e-02, -2.7796e-02,  1.1717e-02,  1.2089e-02, -8.2438e-03,\n",
       "                      -2.0591e-02,  9.8630e-03,  2.4021e-02,  1.5796e-02, -1.7641e-02,\n",
       "                       9.3384e-04, -1.9839e-02,  1.6719e-03, -9.9259e-03,  4.0366e-03,\n",
       "                       2.1673e-03,  3.4141e-02,  3.1908e-02,  3.0063e-02,  6.2937e-03,\n",
       "                      -1.6742e-02, -6.2195e-03, -1.7928e-04, -1.5347e-02, -1.7418e-02,\n",
       "                       3.4965e-02,  3.0178e-02, -1.3911e-02,  1.2578e-02, -2.5354e-03,\n",
       "                       2.7966e-02,  2.4794e-03,  5.4618e-03, -2.1024e-02,  2.3608e-02,\n",
       "                       2.9646e-02, -3.5194e-02, -1.7299e-02, -3.3869e-02,  1.0899e-02,\n",
       "                      -1.5039e-02,  3.3215e-02,  2.3139e-02,  2.2969e-02, -1.0238e-02,\n",
       "                      -1.3675e-02,  7.5436e-04,  3.5644e-02, -1.9252e-02,  3.2457e-02,\n",
       "                      -1.0157e-02,  1.5744e-02,  1.8722e-02, -7.6944e-03, -1.0118e-02,\n",
       "                      -4.6595e-03,  1.8831e-02,  3.2981e-02,  3.4189e-02,  6.4843e-04,\n",
       "                       2.0617e-02,  1.1205e-02, -4.5788e-03, -1.6308e-02,  1.8986e-02,\n",
       "                       7.8482e-03,  3.4019e-02,  6.4228e-03,  2.2859e-02, -2.9317e-02,\n",
       "                       1.6170e-02, -2.3731e-02,  2.2793e-02,  1.1261e-02, -1.5634e-02,\n",
       "                      -4.0174e-03, -3.5669e-02,  2.3714e-02, -1.9851e-02, -3.0081e-04,\n",
       "                      -1.2052e-02,  1.3301e-03,  3.2293e-03, -2.1303e-02,  5.9055e-03,\n",
       "                      -1.7857e-02, -2.1628e-02, -3.8339e-03,  1.9626e-02,  1.4754e-02,\n",
       "                      -4.7133e-03, -3.4607e-02,  2.0427e-02, -9.4791e-03,  1.3858e-02,\n",
       "                      -4.5002e-03,  2.2173e-02,  2.4665e-02, -1.2479e-02, -1.0359e-02,\n",
       "                       3.3022e-02, -2.8862e-02,  2.3747e-02,  6.9415e-03, -3.3230e-02,\n",
       "                      -2.6182e-03,  1.6316e-02,  2.3254e-02, -2.8074e-02,  7.4501e-03,\n",
       "                       1.5059e-02,  2.5370e-02])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.0436,  0.0163, -0.0191,  ..., -0.0192, -0.0290, -0.0081],\n",
       "                      [-0.0411, -0.0117, -0.0162,  ..., -0.0014,  0.0092, -0.0239],\n",
       "                      [ 0.0156,  0.0162,  0.0116,  ..., -0.0356, -0.0314, -0.0188],\n",
       "                      ...,\n",
       "                      [ 0.0252, -0.0384, -0.0077,  ...,  0.0215,  0.0270,  0.0256],\n",
       "                      [-0.0216, -0.0152, -0.0154,  ...,  0.0053, -0.0342, -0.0031],\n",
       "                      [-0.0121, -0.0231, -0.0325,  ..., -0.0212, -0.0179,  0.0193]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 3.8273e-02, -2.7749e-02,  1.2609e-02,  4.3682e-02,  3.1508e-02,\n",
       "                       2.3067e-02,  3.9348e-02, -5.2472e-03, -1.6198e-02, -3.3117e-02,\n",
       "                       4.2106e-02, -1.2919e-03,  5.6132e-03, -2.8104e-02, -3.3477e-02,\n",
       "                       4.2650e-02,  1.4019e-02,  3.3034e-02,  2.2176e-02,  1.9437e-02,\n",
       "                       6.5525e-03,  3.7015e-02, -2.2304e-02,  2.1028e-02, -4.3871e-02,\n",
       "                       1.4634e-02,  3.7684e-02,  1.6795e-02, -3.2547e-02, -3.7081e-02,\n",
       "                       3.9002e-02,  3.0867e-02,  2.3112e-02,  4.8419e-03,  3.9206e-02,\n",
       "                       1.2945e-02, -2.7135e-03,  2.0407e-02,  1.1157e-02,  1.3127e-02,\n",
       "                       4.0997e-02, -1.4489e-02, -8.3493e-03,  3.7416e-02, -2.8285e-02,\n",
       "                       3.1548e-02,  1.0047e-02, -1.4912e-02,  3.9118e-03, -2.4485e-02,\n",
       "                      -2.7802e-02, -4.4069e-02,  6.6717e-04,  1.5130e-02,  4.1504e-02,\n",
       "                      -7.6238e-05,  2.2748e-02, -2.3858e-02,  4.3816e-02, -3.8694e-02,\n",
       "                      -2.4300e-02,  1.6677e-02, -2.6879e-02, -2.7470e-02, -3.9375e-02,\n",
       "                       3.9050e-02, -9.6743e-03,  3.2700e-02,  1.9790e-02,  3.7903e-02,\n",
       "                      -2.8443e-02, -4.8521e-03,  3.3390e-02, -1.0665e-02, -3.9509e-03,\n",
       "                      -1.6068e-03, -1.1210e-02,  2.5136e-02,  2.7027e-02, -7.6821e-03,\n",
       "                       3.6540e-02,  3.9206e-02,  1.3436e-02, -3.8679e-02,  1.9136e-02,\n",
       "                       3.5277e-03,  3.4890e-02,  3.3342e-02,  2.9810e-02,  3.1130e-02,\n",
       "                      -1.6414e-02, -2.7898e-03,  1.8139e-02,  4.0619e-02, -3.0840e-03,\n",
       "                      -2.1391e-02, -2.5684e-02, -1.6286e-02, -1.1043e-02, -3.0889e-02,\n",
       "                      -2.3440e-03,  2.7635e-02, -3.6048e-02, -2.8167e-02,  2.1576e-02,\n",
       "                       2.4273e-02,  2.0349e-02, -9.5940e-03,  2.5543e-02,  4.2409e-02,\n",
       "                      -5.5000e-03,  2.7066e-02, -3.1596e-02, -3.6094e-02,  4.8720e-03,\n",
       "                      -3.2118e-02,  2.7771e-02,  4.0091e-02, -1.9639e-03, -3.0141e-02,\n",
       "                       1.2851e-03,  6.9190e-03,  3.5155e-02,  2.5258e-02,  3.8063e-02,\n",
       "                       2.6144e-02,  2.0129e-02, -7.1706e-03, -3.2529e-02,  5.8218e-03,\n",
       "                      -1.0816e-02, -9.2771e-03,  3.1359e-02,  7.4221e-04,  3.2897e-02,\n",
       "                       1.4790e-02, -3.5826e-02,  2.6857e-02,  1.3405e-02,  2.4600e-02,\n",
       "                       2.1937e-02,  1.8074e-02, -1.4390e-02, -4.2338e-02, -1.4530e-02,\n",
       "                      -2.3241e-02, -3.6264e-02, -2.0231e-02, -1.4095e-02, -1.0566e-02,\n",
       "                       2.5233e-02,  3.4273e-02, -1.6971e-02,  9.6036e-03,  3.6260e-02,\n",
       "                       1.7243e-02, -1.9951e-02,  2.8595e-02, -3.9140e-02,  2.9649e-02,\n",
       "                      -2.9907e-02,  2.9560e-02, -2.7068e-02,  3.1995e-02,  1.2249e-04,\n",
       "                      -1.0681e-02, -3.0060e-02, -1.8699e-02, -2.7352e-02,  9.8815e-03,\n",
       "                      -4.3545e-02, -4.1619e-03,  1.3240e-02, -3.6142e-02,  3.5201e-02,\n",
       "                       2.7487e-02, -2.7074e-02, -2.7371e-02,  1.3664e-02, -3.7146e-02,\n",
       "                      -5.0117e-03,  1.1680e-02,  1.0797e-02, -3.5686e-02, -1.4808e-02,\n",
       "                       2.1266e-02,  1.3344e-02,  5.7520e-03, -3.4102e-02,  2.8397e-02,\n",
       "                      -2.0254e-02, -3.4907e-02,  2.7136e-02,  1.5528e-02,  1.5681e-03,\n",
       "                      -3.3919e-02, -2.4043e-02, -3.8019e-02, -2.7097e-02, -3.6223e-02,\n",
       "                       3.2051e-02, -2.6834e-02, -3.0710e-02,  3.4241e-02,  9.2708e-03,\n",
       "                      -1.8942e-02, -2.6110e-02,  2.6371e-02,  1.0410e-02,  8.7786e-03,\n",
       "                      -3.7870e-02, -2.0985e-02,  2.5035e-02, -4.0851e-02, -1.0274e-02,\n",
       "                       2.2712e-02,  3.3032e-02,  5.5854e-03, -3.5991e-02, -3.8919e-02,\n",
       "                       4.3761e-02,  5.7623e-03, -1.0717e-02,  8.2439e-03, -4.3931e-02,\n",
       "                      -2.6998e-02, -4.0019e-02,  3.4497e-02, -2.8996e-02,  3.3706e-02,\n",
       "                      -2.0468e-02, -2.4354e-02, -3.1998e-03, -2.3300e-02,  1.1846e-02,\n",
       "                       3.1066e-02, -4.0249e-02,  1.8124e-02,  3.0783e-02, -1.2569e-02,\n",
       "                      -1.7861e-02, -1.8916e-02, -2.7981e-02,  2.3996e-02,  3.4994e-02,\n",
       "                      -8.7823e-03,  1.7470e-02,  2.0962e-02, -9.8528e-03, -4.5957e-03,\n",
       "                       1.1430e-02, -2.4674e-02, -2.4439e-02,  9.8221e-03, -5.8741e-03,\n",
       "                      -4.0041e-02,  2.3106e-02,  1.0566e-02,  3.2914e-02, -1.9519e-02,\n",
       "                      -3.5477e-02, -4.1039e-02,  2.5177e-02,  2.9566e-02, -3.9299e-02,\n",
       "                      -1.9826e-02,  3.0211e-03,  2.6679e-02, -9.5586e-03, -2.7278e-02,\n",
       "                      -1.3541e-02, -1.7770e-02,  4.2921e-02,  2.0686e-02, -3.4880e-02,\n",
       "                      -4.7010e-04,  1.4232e-02,  3.8535e-03,  3.3060e-02,  3.5372e-02,\n",
       "                       1.0463e-02,  3.0026e-06,  4.4656e-03, -2.5170e-03, -3.9928e-02,\n",
       "                       3.2900e-02, -9.8198e-03, -4.1443e-02,  1.1095e-02,  3.1761e-02,\n",
       "                       2.0196e-02, -2.1081e-02,  1.1538e-02, -6.3946e-03, -2.9221e-02,\n",
       "                       8.0497e-03,  4.3662e-02, -2.3575e-02, -4.1981e-02, -2.8469e-02,\n",
       "                       3.2845e-02,  3.5507e-02, -2.1453e-02,  3.4867e-02,  2.1545e-02,\n",
       "                      -4.1381e-02,  5.6694e-03, -4.0966e-02,  3.0203e-02, -1.9038e-02,\n",
       "                       1.3477e-03, -4.3854e-02,  3.3348e-02, -2.8804e-03, -4.7997e-03,\n",
       "                       2.5575e-02,  3.9671e-02,  4.3778e-02,  2.0312e-02,  3.6453e-02,\n",
       "                      -2.9263e-02,  1.9156e-02, -1.8017e-03, -1.3734e-02,  3.9526e-02,\n",
       "                      -1.6467e-02, -2.7212e-02, -1.8220e-02, -1.5931e-02,  6.4061e-03,\n",
       "                       2.4739e-02,  2.4199e-02,  1.7252e-03, -3.7172e-02,  4.0373e-02,\n",
       "                      -3.9580e-02, -4.2229e-02,  1.8870e-02,  3.8826e-02, -2.5424e-02,\n",
       "                      -3.6028e-02,  1.2167e-02,  3.1913e-02, -4.1027e-02,  2.4968e-02,\n",
       "                      -2.9862e-02, -2.0455e-03, -3.3882e-02,  2.1273e-02,  9.2205e-03,\n",
       "                       1.3891e-02, -3.5446e-03,  2.0403e-02, -2.6041e-02, -3.5548e-02,\n",
       "                      -3.0288e-02,  1.4206e-02, -3.7902e-02, -4.3007e-02,  2.5123e-02,\n",
       "                      -1.6536e-02, -2.2766e-02, -2.1892e-02, -1.3569e-02, -1.2724e-02,\n",
       "                       2.7821e-02, -2.4716e-02,  1.2779e-02, -6.1035e-03,  2.3829e-02,\n",
       "                      -1.3140e-02,  3.9841e-02, -3.9965e-02, -2.2352e-02,  7.0305e-03,\n",
       "                      -1.2297e-02, -1.0203e-02, -1.0956e-02, -3.6684e-02,  3.9954e-02,\n",
       "                      -3.0111e-02,  2.1087e-02,  1.5100e-02, -3.8040e-02,  3.6584e-02,\n",
       "                      -2.1294e-02,  1.3924e-02,  3.7147e-02, -1.5238e-02,  1.5464e-02,\n",
       "                       8.4671e-03, -4.9609e-03, -3.2138e-03,  4.1412e-02,  1.4399e-03,\n",
       "                       1.3519e-02, -1.5283e-02, -6.1979e-04, -9.0411e-03,  3.2771e-02,\n",
       "                       8.7946e-04,  1.8624e-02, -8.5358e-03,  2.9298e-02,  3.0346e-02,\n",
       "                      -1.5598e-02,  5.9033e-04,  2.0682e-02,  1.0736e-02, -7.5899e-03,\n",
       "                       2.2665e-03,  3.0149e-02,  2.5471e-02, -1.6593e-02,  1.4062e-02,\n",
       "                       1.8536e-02, -1.7026e-02,  2.3474e-02, -2.0878e-02, -2.8492e-02,\n",
       "                      -2.8779e-02, -2.0442e-02, -7.0005e-03,  3.0419e-02, -4.9190e-03,\n",
       "                       7.8532e-03, -2.5681e-02, -7.9022e-03,  5.1945e-03, -3.3933e-03,\n",
       "                      -3.1329e-02,  3.5103e-02, -3.3933e-02,  1.8836e-02,  3.8153e-02,\n",
       "                      -4.3561e-02,  1.5058e-02, -3.0533e-02, -4.2348e-02,  2.8323e-02,\n",
       "                       4.0494e-02,  3.9905e-02,  3.8035e-02,  3.0270e-03,  8.1240e-03,\n",
       "                      -2.7433e-02,  3.7473e-02, -7.4500e-03,  1.6579e-02, -7.1195e-03,\n",
       "                       3.2173e-02,  2.3248e-02, -3.9915e-02,  2.6554e-02, -1.2698e-02,\n",
       "                      -9.9278e-03,  3.3699e-03,  2.1406e-02,  2.3862e-02, -4.2411e-02,\n",
       "                       3.6074e-02, -1.8427e-02, -8.8552e-04,  8.0322e-03,  1.8299e-02,\n",
       "                       2.5020e-02,  2.8607e-02, -1.1611e-02, -1.0712e-02, -4.1782e-02,\n",
       "                       3.2032e-02, -1.3004e-02,  2.3178e-02,  1.7099e-02,  3.6791e-02,\n",
       "                       4.9416e-03,  3.9844e-02,  3.3446e-02,  2.2496e-02,  2.2003e-02,\n",
       "                      -1.7887e-02, -1.6873e-02,  6.4608e-04,  9.4451e-03,  3.4799e-02,\n",
       "                      -2.8670e-02, -9.5473e-03,  2.0287e-02, -2.1351e-02,  1.2269e-02,\n",
       "                      -2.8091e-02, -2.8359e-02, -7.0937e-03,  2.2377e-02,  2.9411e-02,\n",
       "                      -3.9403e-02, -8.8950e-03,  2.9581e-02, -1.9611e-02,  9.3650e-03,\n",
       "                       4.1901e-02, -3.6826e-02, -7.6973e-03, -1.7398e-02, -7.2896e-03,\n",
       "                      -7.6217e-03,  4.0408e-03,  4.0616e-02,  4.3155e-02, -1.1531e-02,\n",
       "                       3.6590e-02,  2.6350e-02])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.0115,  0.0244, -0.0087,  ...,  0.0028,  0.0074, -0.0022],\n",
       "                      [-0.0315, -0.0011,  0.0262,  ...,  0.0003, -0.0299, -0.0280],\n",
       "                      [ 0.0006,  0.0077,  0.0264,  ...,  0.0193,  0.0185, -0.0151],\n",
       "                      ...,\n",
       "                      [-0.0062,  0.0048, -0.0135,  ..., -0.0081,  0.0092,  0.0233],\n",
       "                      [-0.0061,  0.0087,  0.0303,  ...,  0.0330, -0.0228,  0.0193],\n",
       "                      [ 0.0432,  0.0282, -0.0317,  ...,  0.0271, -0.0003, -0.0027]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0161, -0.0182,  0.0418,  0.0078,  0.0429, -0.0221, -0.0246, -0.0080,\n",
       "                      -0.0106, -0.0325]))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92263afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180132bd",
   "metadata": {},
   "source": [
    "### 方式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "908f3e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"models/mlp_model.pth\")\n",
    "mlp_load = torch.load(\"models/mlp_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "805c680f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  (fc3): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a359ba",
   "metadata": {},
   "source": [
    "### 方式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6365f3d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (245471031.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 6\u001b[0;36m\u001b[0m\n\u001b[0;31m    ...\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            ...\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TheModelClass(*args, **kwargs)\n",
    "optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
